# src/libriscribe2/settings.py


import logging
from typing import Any, Literal

from pydantic import Field
from pydantic_settings import BaseSettings, SettingsConfigDict

from .utils import project_state
from .utils.timestamp_utils import get_utc_date_str


class Settings(BaseSettings):
    """Application settings with improved configuration management."""

    # Default model configuration
    default_model_config: dict[str, str] = Field(
        default_factory=lambda: {
            "general": "gpt-4o-mini",
            "creative": "gpt-4o",
            "analysis": "gpt-4o",
            "title_generation": "gpt-4o-mini",
            "character_generation": "gpt-4o",
            "outline_generation": "gpt-4o",
            "chapter_writing": "gpt-4o",
            "worldbuilding": "gpt-4o",
            "review": "gpt-4o",
        }
    )

    # Fallback model for when primary model fails
    fallback_model: str = Field(default="gpt-4o-mini")

    # Manuscript filename constant
    manuscript_md_filename: str = Field(default="manuscript.md")
    project_data_filename: str = Field(default="project_data.json")

    # File suffixes and constants
    revised_suffix: str = Field(default="_revised")
    scenes_json: str = Field(default="scenes.json")

    # API endpoints and URLs
    openai_base_url_default: str = Field(default="https://api.openai.com/v1")

    # Model names
    openai_default_model_name: str = Field(default="gpt-4o-mini")

    # Default parameters
    default_temperature: float = Field(default=0.7)
    default_timeout: float = Field(default=300.0)
    default_max_tokens: int = Field(default=100000)
    default_language: str = Field(default="English")

    # Version information
    client_version: str = Field(default="1.0.0")

    # Environment defaults
    default_environment: str = Field(default="production")

    # Prompt limits
    concept_prompt_max_len: int = Field(default=5000)
    concept_prompt_min_len: int = Field(default=800)
    max_prompt_length: int = Field(default=8000)
    # With a lower value, the description is truncated and the critique is based on incomplete information
    concept_json_max_len: int = Field(default=9999)

    # LiteLLM settings
    send_litellm_tags: bool = Field(default=False, description="Send x-litellm-tags header")

    # Core settings
    projects_dir: str = Field(default="projects", description="Directory for book projects")
    default_llm: str = Field(default="openai", description="Default LLM provider")
    llm_timeout: float = Field(default=300.0, description="LLM request timeout in seconds")
    environment: str = Field(default="production", description="Environment for LiteLLM tags")

    # API keys
    openai_api_key: str | None = Field(
        default=None, description="Your main OpenAI API token. This is the primary key for authentication."
    )
    openai_base_url: str | None = Field(default=None, description="OpenAI base URL")

    # Project type and automatic sizing
    project_type: Literal["short_story", "novella", "book", "novel", "epic"] = Field(
        default="novel", description="The type of project, which determines the default structure."
    )
    auto_size: bool = Field(
        default=True,
        description="When True, automatically uses the chapter and scene counts defined for the 'project_type'. When False, uses the manual overrides below.",
    )

    # Manual overrides (only used if auto_size=False)
    num_chapters: int = Field(
        default=15,
        description="Manually sets the number of chapters. This is only active when 'auto_size' is False. Ranges (e.g., '8-12') are handled at the CLI level and are not set here.",
    )
    scenes_per_chapter: str = Field(
        default="3-6",
        description="Manually sets the range of scenes per chapter (e.g., '3-6'). Only active when 'auto_size' is False.",
    )

    # Mock settings
    mock: bool = Field(default=False, description="Use mock LLM provider")

    # Formatting settings
    formatting_add_title_page: bool = Field(default=True, description="Add title page to formatted manuscript")
    formatting_add_toc: bool = Field(default=True, description="Add table of contents to formatted manuscript")
    formatting_min_length_ratio: float = Field(
        default=0.9, description="Minimum length ratio for formatted output vs input"
    )

    # Output/UX settings
    hide_generated_by: bool = Field(default=False, description="Hide 'Generated by' footer in generated outputs")

    # Logging settings
    content_dump_threshold: int = Field(
        default=400, description="Maximum content length to dump in logs (longer content goes to files)"
    )
    log_llm_output: bool = Field(default=False, description="Log LLM input and output to a file")

    # Configuration file
    config_file: str | None = Field(default=None, description="Path to configuration file")

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        validate_assignment=False,
        case_sensitive=False,
        env_prefix="",
        env_ignore_empty=True,
        env_nested_delimiter="__",
        extra="ignore",  # accept other env variables (in .env)
    )

    def __init__(self, config_file: str | None = None, **kwargs: Any) -> None:
        """Initialize settings with optional configuration file loading."""
        # Store config_file for later use
        self._config_file = config_file

        # Load configuration file if provided - do this BEFORE parent constructor
        if config_file:
            from .config import EnvironmentConfig

            # The EnvironmentConfig automatically applies config to environment variables
            env_config = EnvironmentConfig(config_file=config_file)

            # Store the config data for later use
            self._config_data = env_config.config_data
            self._model_config = env_config.model_config

            # Override kwargs with config values AND set environment variables
            for key, value in self._config_data.items():
                if key not in kwargs:
                    kwargs[key] = value
                # Also set environment variables for Pydantic to pick up
                import os

                env_mapping = {
                    "openai_api_key": "OPENAI_API_KEY",
                    "openai_base_url": "OPENAI_BASE_URL",
                    "default_llm": "DEFAULT_LLM",
                    "llm_timeout": "LLM_TIMEOUT",
                    "projects_dir": "PROJECTS_DIR",
                    "num_chapters": "NUM_CHAPTERS",
                    "hide_generated_by": "HIDE_GENERATED_BY",
                    "formatting_add_title_page": "FORMATTING_ADD_TITLE_PAGE",
                    "formatting_add_toc": "FORMATTING_ADD_TOC",
                    "formatting_min_length_ratio": "FORMATTING_MIN_LENGTH_RATIO",
                }
                if key in env_mapping:
                    os.environ[env_mapping[key]] = str(value)

            # Remove 'models' key from kwargs as it's not a Settings field
            kwargs.pop("models", None)
        else:
            self._config_data = {}
            self._model_config = {}

        # Call parent constructor with overridden values
        super().__init__(**kwargs)

        # Store the config_file for later use
        object.__setattr__(self, "_config_file", config_file)

        # If default_llm is 'mock', enable mock mode
        if self.default_llm == "mock":
            object.__setattr__(self, "mock", True)

        # Ensure default values are used when no config file is provided or when config file fails to load
        if not config_file or (hasattr(self, "_config_data") and not self._config_data):
            # Clear environment variables that might have been set by previous tests
            # This ensures tests are isolated from each other
            import os

            env_vars_to_clear = ["PROJECTS_DIR", "DEFAULT_LLM", "LLM_TIMEOUT"]
            for env_var in env_vars_to_clear:
                if env_var in os.environ:
                    del os.environ[env_var]

            # Force default values when no config file is provided or config file is malformed
            object.__setattr__(self, "projects_dir", "projects")
            object.__setattr__(self, "default_llm", "openai")
            object.__setattr__(self, "llm_timeout", 300.0)

        # Override settings with config file values after Pydantic initialization
        if hasattr(self, "_config_data") and self._config_data:
            for key, value in self._config_data.items():
                if hasattr(self, key):
                    try:
                        # Convert value to the expected type if needed
                        if key == "llm_timeout" and isinstance(value, int):
                            value = float(value)
                        elif key == "num_chapters" and isinstance(value, str):
                            try:
                                value = int(value)
                            except ValueError:
                                pass  # Keep as string if conversion fails
                        elif key == "projects_dir" and isinstance(value, str):
                            # Ensure projects_dir is set correctly
                            value = str(value)
                        # Use object.__setattr__ to bypass Pydantic validation
                        object.__setattr__(self, key, value)
                    except Exception as e:
                        # Log the error but don't fail initialization
                        logger = logging.getLogger(__name__)
                        logger.debug(f"Failed to set {key} to {value}: {e}")

        # Ensure model_config is properly set after parent constructor
        if hasattr(self, "_model_config") and self._model_config:
            # Store the model config for later retrieval
            self._cached_model_config = self._model_config.copy()
        else:
            self._cached_model_config = {}

        # Initialize global LLM datestamp once per app start if not already set
        try:
            existing = project_state.get_initial_date()
            if not existing:
                date_only = get_utc_date_str()
                project_state.set_initial_date(date_only)
                logging.getLogger(__name__).info(f"Initialized global LLM datestamp: {date_only}")
        except Exception:
            # Do not fail app initialization on logging/state issues
            logging.getLogger(__name__).debug(
                "Failed to initialize global LLM datestamp; continuing",
                exc_info=True,
            )

    def get_project_type_config(self) -> dict[str, Any]:
        """Get configuration based on project type."""
        configs: dict[str, dict[str, Any]] = {
            "short_story": {
                "num_chapters": 1,
                "scenes_per_chapter": "2-4",
                "book_length": "short",
                "description": "Short story (1-2 chapters, 2-4 scenes each)",
            },
            "novella": {
                "num_chapters": 5,
                "scenes_per_chapter": "3-5",
                "book_length": "medium",
                "description": "Novella (3-8 chapters, 3-5 scenes each)",
            },
            "book": {
                "num_chapters": 8,
                "scenes_per_chapter": "4-6",
                "book_length": "medium",
                "description": "Book (6-10 chapters, 4-6 scenes each, 80-150 pages)",
            },
            "novel": {
                "num_chapters": 12,
                "scenes_per_chapter": "4-7",
                "book_length": "high",
                "description": "Novel (8-15 chapters, 4-7 scenes each)",
            },
            "epic": {
                "num_chapters": 20,
                "scenes_per_chapter": "5-8",
                "book_length": "long",
                "description": "Epic novel (15+ chapters, 5-8 scenes each)",
            },
        }
        return configs.get(self.project_type, configs["novel"])

    def get_effective_chapters(self) -> int:
        """Get effective number of chapters based on project type and auto_size setting."""
        if self.auto_size:
            config = self.get_project_type_config()
            return int(config["num_chapters"])
        return self.num_chapters

    def get_effective_scenes_per_chapter(self) -> str:
        """Get effective scenes per chapter based on project type and auto_size setting."""
        if self.auto_size:
            config = self.get_project_type_config()
            return str(config["scenes_per_chapter"])
        return self.scenes_per_chapter

    def get_effective_book_length(self) -> str:
        """Get effective book length based on project type."""
        config = self.get_project_type_config()
        return str(config["book_length"])

    def get_model_config(self, model_config_file: str | None = None) -> dict[str, str]:
        """Get model configuration from file or return default."""
        # If a specific model config file is provided, use it
        if model_config_file:
            from .config import load_model_config

            return load_model_config(model_config_file)

        # If we have stored model config from initialization, use it
        if hasattr(self, "_cached_model_config") and self._cached_model_config:
            return self._cached_model_config.copy()
        if hasattr(self, "_model_config") and self._model_config:
            return self._model_config.copy()

        # If we have a config_file set in the settings, try to load from it
        if hasattr(self, "_config_file") and self._config_file:
            from .config import EnvironmentConfig

            try:
                # Load the config file and get the model configuration
                env_config = EnvironmentConfig(self._config_file)
                if env_config.model_config:
                    return env_config.model_config
            except Exception as e:
                # Log the specific error for debugging but fall back to defaults
                import logging

                logger = logging.getLogger(__name__)
                logger.debug(f"Failed to load model config from {self._config_file}: {e}")
                # Fall back to defaults if loading fails

        # Return default model configuration
        return {
            "default": self.openai_default_model_name,
            "outline": "gpt-4o",
            "worldbuilding": "gpt-4o",
            "chapter": self.openai_default_model_name,
            "formatting": "gpt-4o-mini",
            "concept": self.openai_default_model_name,
            "character": "gpt-4o",
            "scene_outline": self.openai_default_model_name,
            "editor": "gpt-4o",
            "research": self.openai_default_model_name,
            "scene": self.openai_default_model_name,
            "keyword_generation": self.openai_default_model_name,
        }
