"""
This type stub file was generated by pyright.
"""

from typing import AsyncGenerator, Awaitable, Callable, List, Optional, Sequence, Union
from autogen_core import CancellationToken, Component, ComponentModel
from autogen_core.code_executor import CodeBlock, CodeExecutor, CodeResult
from autogen_core.model_context import ChatCompletionContext
from autogen_core.models import ChatCompletionClient, LLMMessage
from pydantic import BaseModel
from ..base import Response
from ..messages import BaseAgentEvent, BaseChatMessage
from ._base_chat_agent import BaseChatAgent

event_logger = ...
class CodeExecutorAgentConfig(BaseModel):
    """Configuration for CodeExecutorAgent"""
    name: str
    code_executor: ComponentModel
    model_client: ComponentModel | None = ...
    description: str | None = ...
    sources: List[str] | None = ...
    system_message: str | None = ...
    model_client_stream: bool = ...
    model_context: ComponentModel | None = ...
    supported_languages: List[str] | None = ...


class RetryDecision(BaseModel):
    reason: str
    retry: bool
    ...


class ApprovalRequest(BaseModel):
    """Request for approval of code execution."""
    code: str
    context: List[LLMMessage]
    ...


class ApprovalResponse(BaseModel):
    """Response to approval request."""
    approved: bool
    reason: str
    ...


SyncApprovalFunc = Callable[[ApprovalRequest], ApprovalResponse]
AsyncApprovalFunc = Callable[[ApprovalRequest], Awaitable[ApprovalResponse]]
ApprovalFuncType = Union[SyncApprovalFunc, AsyncApprovalFunc]
class CodeExecutorAgent(BaseChatAgent, Component[CodeExecutorAgentConfig]):
    """(Experimental) An agent that generates and executes code snippets based on user instructions.

    .. note::

        This agent is experimental and may change in future releases.

    It is typically used within a team with another agent that generates code snippets
    to be executed or alone with `model_client` provided so that it can generate code
    based on user query, execute it and reflect on the code result.

    When used with `model_client`, it will generate code snippets using the model
    and execute them using the provided `code_executor`. The model will also reflect on the
    code execution results. The agent will yield the final reflection result from the model
    as the final response.

    When used without `model_client`, it will only execute code blocks found in
    :class:`~autogen_agentchat.messages.TextMessage` messages and returns the output
    of the code execution.

    .. note::

        Using :class:`~autogen_agentchat.agents.AssistantAgent` with
        :class:`~autogen_ext.tools.code_execution.PythonCodeExecutionTool`
        is an alternative to this agent. However, the model for that agent will
        have to generate properly escaped code string as a parameter to the tool.

    Args:
        name (str): The name of the agent.
        code_executor (CodeExecutor): The code executor responsible for executing code received in messages
            (:py:class:`~autogen_ext.code_executors.docker.DockerCommandLineCodeExecutor` recommended. See example below)
        model_client (ChatCompletionClient, optional): The model client to use for inference and generating code.
            If not provided, the agent will only execute code blocks found in input messages.
            Currently, the model must support structured output mode, which is required for
            the automatic retry mechanism to work.
        model_client_stream (bool, optional): If `True`, the model client will be used in streaming mode.
            :meth:`on_messages_stream` and :meth:`BaseChatAgent.run_stream` methods will
            also yield :class:`~autogen_agentchat.messages.ModelClientStreamingChunkEvent`
            messages as the model client produces chunks of response. Defaults to `False`.
        description (str, optional): The description of the agent. If not provided,
            :class:`~autogen_agentchat.agents.CodeExecutorAgent.DEFAULT_AGENT_DESCRIPTION` will be used.
        system_message (str, optional): The system message for the model. If provided, it will be prepended to the messages in the model context when making an inference. Set to `None` to disable.
            Defaults to :class:`~autogen_agentchat.agents.CodeExecutorAgent.DEFAULT_SYSTEM_MESSAGE`. This is only used if `model_client` is provided.
        sources (Sequence[str], optional): Check only messages from the specified agents for the code to execute.
            This is useful when the agent is part of a group chat and you want to limit the code execution to messages from specific agents.
            If not provided, all messages will be checked for code blocks.
            This is only used if `model_client` is not provided.
        max_retries_on_error (int, optional): The maximum number of retries on error. If the code execution fails, the agent will retry up to this number of times.
            If the code execution fails after this number of retries, the agent will yield a reflection result.
        supported_languages (List[str], optional): List of programming languages that will be parsed and executed from agent response;
            others will be ignored. Defaults to DEFAULT_SUPPORTED_LANGUAGES.
        approval_func (Optional[Union[Callable[[ApprovalRequest], ApprovalResponse], Callable[[ApprovalRequest], Awaitable[ApprovalResponse]]]], optional): A function that is called before each code execution to get approval.
            The function takes an ApprovalRequest containing the code to be executed and the current context, and returns an ApprovalResponse.
            The function can be either synchronous or asynchronous. If None (default), all code executions are automatically approved.
            If set, the agent cannot be serialized using :meth:`~autogen_agentchat.agents.CodeExecutorAgent.dump_component`.


    .. note::

        It is recommended that the `CodeExecutorAgent` agent uses a Docker container to execute code. This ensures that model-generated code is executed in an isolated environment. To use Docker, your environment must have Docker installed and running.
        Follow the installation instructions for `Docker <https://docs.docker.com/get-docker/>`_.

    .. note::

        The code executor only processes code that is properly formatted in markdown code blocks using triple backticks.
        For example:

        .. code-block:: text

            ```python
            print("Hello World")
            ```

            # or

            ```sh
            echo "Hello World"
            ```

    In this example, we show how to set up a `CodeExecutorAgent` agent that uses the
    :py:class:`~autogen_ext.code_executors.docker.DockerCommandLineCodeExecutor`
    to execute code snippets in a Docker container. The `work_dir` parameter indicates
    where all executed files are first saved locally before being executed in the Docker container.

        .. code-block:: python

            import asyncio
            from autogen_agentchat.agents import CodeExecutorAgent, ApprovalRequest, ApprovalResponse
            from autogen_agentchat.messages import TextMessage
            from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor
            from autogen_core import CancellationToken


            def simple_approval_func(request: ApprovalRequest) -> ApprovalResponse:
                \"\"\"Simple approval function that requests user input for code execution approval.\"\"\"
                print("Code execution approval requested:")
                print("=" * 50)
                print(request.code)
                print("=" * 50)

                while True:
                    user_input = input("Do you want to execute this code? (y/n): ").strip().lower()
                    if user_input in ['y', 'yes']:
                        return ApprovalResponse(approved=True, reason='Approved by user')
                    elif user_input in ['n', 'no']:
                        return ApprovalResponse(approved=False, reason='Denied by user')
                    else:
                        print("Please enter 'y' for yes or 'n' for no.")


            async def run_code_executor_agent() -> None:
                # Create a code executor agent that uses a Docker container to execute code.
                code_executor = DockerCommandLineCodeExecutor(work_dir="coding")
                await code_executor.start()
                code_executor_agent = CodeExecutorAgent(
                    "code_executor",
                    code_executor=code_executor,
                    approval_func=simple_approval_func
                )

                # Run the agent with a given code snippet.
                task = TextMessage(
                    content='''Here is some code
            ```python
            print('Hello world')
            ```
            ''',
                    source="user",
                )
                response = await code_executor_agent.on_messages([task], CancellationToken())
                print(response.chat_message)

                # Stop the code executor.
                await code_executor.stop()


            asyncio.run(run_code_executor_agent())

    In this example, we show how to set up a `CodeExecutorAgent` agent that uses the
    :py:class:`~docker.types.DeviceRequest` to expose a GPU to the container for cuda-accelerated code execution.

        .. code-block:: python

            import asyncio
            from autogen_agentchat.agents import CodeExecutorAgent
            from autogen_agentchat.messages import TextMessage
            from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor
            from autogen_core import CancellationToken
            from docker.types import DeviceRequest


            async def run_code_executor_agent() -> None:
                # Create a code executor agent that uses a Docker container to execute code.
                code_executor = DockerCommandLineCodeExecutor(
                    work_dir="coding", device_requests=[DeviceRequest(count=-1, capabilities=[["gpu"]])]
                )
                await code_executor.start()
                code_executor_agent = CodeExecutorAgent("code_executor", code_executor=code_executor)

                # Display the GPU information
                task = TextMessage(
                    content='''Here is some code
            ```sh
            nvidia-smi
            ```
            ''',
                    source="user",
                )
                response = await code_executor_agent.on_messages([task], CancellationToken())
                print(response.chat_message)

                # Stop the code executor.
                await code_executor.stop()


            asyncio.run(run_code_executor_agent())

    In the following example, we show how to setup `CodeExecutorAgent` without `model_client` parameter for executing code blocks generated by other agents in a group chat using :py:class:`~autogen_ext.code_executors.docker.DockerCommandLineCodeExecutor`

        .. code-block:: python

            import asyncio

            from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor
            from autogen_ext.models.openai import OpenAIChatCompletionClient

            from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent, ApprovalRequest, ApprovalResponse
            from autogen_agentchat.conditions import MaxMessageTermination
            from autogen_agentchat.teams import RoundRobinGroupChat
            from autogen_agentchat.ui import Console

            termination_condition = MaxMessageTermination(3)


            def group_chat_approval_func(request: ApprovalRequest) -> ApprovalResponse:
                \"\"\"Approval function for group chat that allows basic Python operations.\"\"\"
                # Allow common safe operations
                safe_operations = ["print(", "import ", "def ", "class ", "if ", "for ", "while "]
                if any(op in request.code for op in safe_operations):
                    return ApprovalResponse(approved=True, reason='Safe Python operation')

                # Deny file system operations in group chat
                dangerous_operations = ["open(", "file(", "os.", "subprocess", "eval(", "exec("]
                if any(op in request.code for op in dangerous_operations):
                    return ApprovalResponse(approved=False, reason='File system or dangerous operation not allowed')

                return ApprovalResponse(approved=True, reason='Operation approved')


            async def main() -> None:
                model_client = OpenAIChatCompletionClient(model="gpt-4o")

                # define the Docker CLI Code Executor
                code_executor = DockerCommandLineCodeExecutor(work_dir="coding")

                # start the execution container
                await code_executor.start()

                code_executor_agent = CodeExecutorAgent(
                    "code_executor_agent",
                    code_executor=code_executor,
                    approval_func=group_chat_approval_func
                )
                coder_agent = AssistantAgent("coder_agent", model_client=model_client)

                groupchat = RoundRobinGroupChat(
                    participants=[coder_agent, code_executor_agent], termination_condition=termination_condition
                )

                task = "Write python code to print Hello World!"
                await Console(groupchat.run_stream(task=task))

                # stop the execution container
                await code_executor.stop()


            asyncio.run(main())

        .. code-block:: text

            ---------- user ----------
            Write python code to print Hello World!
            ---------- coder_agent ----------
            Certainly! Here's a simple Python code to print "Hello World!":

            ```python
            print("Hello World!")
            ```

            You can run this code in any Python environment to display the message.
            ---------- code_executor_agent ----------
            Hello World!

    In the following example, we show how to setup `CodeExecutorAgent` with `model_client`
    that can generate its own code without the help of any other agent and executing it in
    :py:class:`~autogen_ext.code_executors.docker.DockerCommandLineCodeExecutor`.
    It also demonstrates using a model-based approval function that reviews the code for safety before execution.

        .. code-block:: python

            import asyncio

            from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor
            from autogen_ext.models.openai import OpenAIChatCompletionClient
            from autogen_core.models import SystemMessage, UserMessage

            from autogen_agentchat.agents import CodeExecutorAgent, ApprovalRequest, ApprovalResponse
            from autogen_agentchat.conditions import TextMessageTermination
            from autogen_agentchat.ui import Console

            termination_condition = TextMessageTermination("code_executor_agent")


            async def main() -> None:
                model_client = OpenAIChatCompletionClient(model="gpt-4o")

                async def model_client_approval_func(request: ApprovalRequest) -> ApprovalResponse:
                    instruction = "Approve or reject the code in the last message based on whether it is dangerous or not. Use the following JSON format for your response: {approved: true/false, reason: 'your reason here'}"
                    response = await model_client.create(
                        messages=[SystemMessage(content=instruction)]
                        + request.context
                        + [UserMessage(content=request.code, source="user")],
                        json_output=ApprovalResponse,
                    )
                    assert isinstance(response.content, str)
                    return ApprovalResponse.model_validate_json(response.content)

                # define the Docker CLI Code Executor
                code_executor = DockerCommandLineCodeExecutor(work_dir="coding")

                # start the execution container
                await code_executor.start()

                code_executor_agent = CodeExecutorAgent(
                    "code_executor_agent",
                    code_executor=code_executor,
                    model_client=model_client,
                    approval_func=model_client_approval_func,
                )

                task = "Write python code to print Hello World!"
                await Console(code_executor_agent.run_stream(task=task))

                # stop the execution container
                await code_executor.stop()


            asyncio.run(main())


        .. code-block:: text

            ---------- user ----------
            Write python code to print Hello World!
            ---------- code_executor_agent ----------
            Certainly! Here is a simple Python code to print "Hello World!" to the console:

            ```python
            print("Hello World!")
            ```

            Let's execute it to confirm the output.
            ---------- code_executor_agent ----------
            Hello World!

            ---------- code_executor_agent ----------
            The code has been executed successfully, and it printed "Hello World!" as expected. If you have any more requests or questions, feel free to ask!

    """
    DEFAULT_TERMINAL_DESCRIPTION = ...
    DEFAULT_AGENT_DESCRIPTION = ...
    DEFAULT_SYSTEM_MESSAGE = ...
    NO_CODE_BLOCKS_FOUND_MESSAGE = ...
    DEFAULT_SUPPORTED_LANGUAGES = ...
    component_config_schema = ...
    component_provider_override = ...
    def __init__(self, name: str, code_executor: CodeExecutor, *, model_client: ChatCompletionClient | None = ..., model_context: ChatCompletionContext | None = ..., model_client_stream: bool = ..., max_retries_on_error: int = ..., description: str | None = ..., system_message: str | None = ..., sources: Sequence[str] | None = ..., supported_languages: List[str] | None = ..., approval_func: Optional[ApprovalFuncType] = ...) -> None:
        ...
    
    @property
    def produced_message_types(self) -> Sequence[type[BaseChatMessage]]:
        """The types of messages that the code executor agent produces."""
        ...
    
    @property
    def model_context(self) -> ChatCompletionContext:
        """
        The model context in use by the agent.
        """
        ...
    
    async def on_messages(self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken) -> Response:
        ...
    
    async def on_messages_stream(self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """
        Process the incoming messages with the assistant agent and yield events/responses as they happen.
        """
        ...
    
    async def extract_code_blocks_from_messages(self, messages: Sequence[BaseChatMessage]) -> List[CodeBlock]:
        ...
    
    async def execute_code_block(self, code_blocks: List[CodeBlock], cancellation_token: CancellationToken) -> CodeResult:
        ...
    
    async def on_reset(self, cancellation_token: CancellationToken) -> None:
        """Its a no-op as the code executor agent has no mutable state."""
        ...
    
