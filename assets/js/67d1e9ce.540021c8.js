"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[377],{5217:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"development/ai-testing-best-practices","title":"AI Testing and Mock System Best Practices","description":"Overview","source":"@site/docs/development/ai-testing-best-practices.md","sourceDirName":"development","slug":"/development/ai-testing-best-practices","permalink":"/libriscribe2/docs/development/ai-testing-best-practices","draft":false,"unlisted":false,"editUrl":"https://github.com/guerra2fernando/libriscribe2/tree/main/docs/docs/development/ai-testing-best-practices.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Development Scripts","permalink":"/libriscribe2/docs/development/SCRIPTS"},"next":{"title":"AutoGen Best Practices for LibriScribe","permalink":"/libriscribe2/docs/development/autogen-best-practices"}}');var i=s(4848),r=s(8453);const a={},c="AI Testing and Mock System Best Practices",o={},l=[{value:"Overview",id:"overview",level:2},{value:"\ud83c\udfaf Core Requirements (Requirement 11)",id:"-core-requirements-requirement-11",level:2},{value:"\ud83c\udfd7\ufe0f Architecture Overview",id:"\ufe0f-architecture-overview",level:2},{value:"\ud83d\udccb Best Practice #1: Interface Consistency",id:"-best-practice-1-interface-consistency",level:2},{value:"Requirement: Mock responses must maintain identical interfaces to real AI calls (11.4)",id:"requirement-mock-responses-must-maintain-identical-interfaces-to-real-ai-calls-114",level:3},{value:"\ud83c\udfad Best Practice #2: Scenario-Based Testing",id:"-best-practice-2-scenario-based-testing",level:2},{value:"Requirement: Support different mock scenarios (success, failure, edge cases) (11.3)",id:"requirement-support-different-mock-scenarios-success-failure-edge-cases-113",level:3},{value:"\ud83d\udcf9 Best Practice #3: Record and Playback System",id:"-best-practice-3-record-and-playback-system",level:2},{value:"Requirement: Allow recording and playback of AI interactions for consistent testing (11.2)",id:"requirement-allow-recording-and-playback-of-ai-interactions-for-consistent-testing-112",level:3},{value:"\u2699\ufe0f Best Practice #4: API Key-Based Switching",id:"\ufe0f-best-practice-4-api-key-based-switching",level:2},{value:"Requirement: Use configuration flags without code changes (11.6)",id:"requirement-use-configuration-flags-without-code-changes-116",level:3},{value:"\ud83d\udcca Best Practice #5: Coverage and Metrics",id:"-best-practice-5-coverage-and-metrics",level:2},{value:"Requirement: Provide metrics on test coverage and validation accuracy (11.5)",id:"requirement-provide-metrics-on-test-coverage-and-validation-accuracy-115",level:3},{value:"\ud83e\uddea Best Practice #6: Comprehensive Test Framework",id:"-best-practice-6-comprehensive-test-framework",level:2},{value:"\ud83d\udcf9 Best Practice #7: Live Response Population",id:"-best-practice-7-live-response-population",level:2},{value:"\ud83c\udfaf Best Practice #8: Accuracy Validation",id:"-best-practice-8-accuracy-validation",level:2},{value:"\ud83d\udd04 Best Practice #8: Regression Testing",id:"-best-practice-8-regression-testing",level:2},{value:"\ud83d\ude80 Best Practice #9: Performance Testing",id:"-best-practice-9-performance-testing",level:2},{value:"\ud83d\udcc8 Best Practice #10: Monitoring and Alerting",id:"-best-practice-10-monitoring-and-alerting",level:2},{value:"\ud83d\udee0\ufe0f Implementation Checklist",id:"\ufe0f-implementation-checklist",level:2},{value:"Phase 1: Basic Mock System",id:"phase-1-basic-mock-system",level:3},{value:"Phase 2: Advanced Features",id:"phase-2-advanced-features",level:3},{value:"Phase 3: Production Readiness",id:"phase-3-production-readiness",level:3},{value:"Phase 4: Optimization",id:"phase-4-optimization",level:3},{value:"\ud83d\udcda Usage Examples",id:"-usage-examples",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Test Framework Usage",id:"test-framework-usage",level:3},{value:"Coverage Analysis",id:"coverage-analysis",level:3},{value:"\ud83c\udfaf Key Benefits",id:"-key-benefits",level:2},{value:"\ud83d\udccb Compliance with Requirements",id:"-compliance-with-requirements",level:2},{value:"\ud83d\ude80 Getting Started",id:"-getting-started",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"ai-testing-and-mock-system-best-practices",children:"AI Testing and Mock System Best Practices"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:["This document outlines comprehensive best practices for AI testing and mocking in the LibriScribe validation system, implementing ",(0,i.jsx)(n.strong,{children:"Requirement 11: AI Testing and Mock System"})," specifications."]}),"\n",(0,i.jsx)(n.h2,{id:"-core-requirements-requirement-11",children:"\ud83c\udfaf Core Requirements (Requirement 11)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mock AI responses that simulate real AI behavior"})," (11.1)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Record and playback of AI interactions"})," for consistent testing (11.2)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Support different mock scenarios"})," (success, failure, edge cases) (11.3)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Maintain same interface and data structures"})," as real AI calls (11.4)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Provide metrics on test coverage and validation accuracy"})," (11.5)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration flags for switching"})," between mock and real AI (11.6)"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-architecture-overview",children:"\ud83c\udfd7\ufe0f Architecture Overview"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[Environment Variables] --\x3e B[AI Mock Manager]\n    A --\x3e C{OPENAI_API_KEY Set?}\n\n    C --\x3e|Yes| D[Real AI Mode]\n    C --\x3e|No| E[Mock Mode]\n\n    D --\x3e F[OpenAI SDK]\n    F --\x3e G[LiteLLM Proxy]\n    G --\x3e H[AI Providers]\n\n    E --\x3e I[Mock Response Generator]\n    E --\x3e J[Recorded Interactions]\n\n    D --\x3e K[Auto Recording]\n    K --\x3e J\n\n    I --\x3e L[Scenario-Based Responses]\n    J --\x3e M[Playback System]\n\n    N[Validation Engine] --\x3e B\n    O[Test Framework] --\x3e B\n    P[Coverage Reporter] --\x3e Q[Usage Statistics]\n"})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-1-interface-consistency",children:"\ud83d\udccb Best Practice #1: Interface Consistency"}),"\n",(0,i.jsx)(n.h3,{id:"requirement-mock-responses-must-maintain-identical-interfaces-to-real-ai-calls-114",children:"Requirement: Mock responses must maintain identical interfaces to real AI calls (11.4)"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Implementation:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'@dataclass\nclass MockResponse:\n    """Identical structure to real AI response"""\n    content: str              # AI response content\n    model: str               # Model used (e.g., "gpt-4")\n    tokens_used: int         # Token consumption\n    cost: float              # API cost\n    confidence: float        # Response confidence (0.0-1.0)\n    metadata: Dict[str, Any] # Additional metadata\n    timestamp: datetime      # Response timestamp\n    scenario: MockScenario   # Mock scenario used\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Use identical data structures for mock and real responses"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Maintain same error handling patterns"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Preserve response timing characteristics"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Include realistic token usage and cost calculations"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Support same metadata fields as real AI responses"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Both mock and real AI return identical interface\nmock_response = await mock_manager.get_ai_response(\n    prompt="Validate content",\n    validator_id="content_validator",\n    use_mock=True  # Mock AI\n)\n\nreal_response = await mock_manager.get_ai_response(\n    prompt="Validate content",\n    validator_id="content_validator",\n    use_mock=False  # Real AI\n)\n\n# Both responses have identical structure\nassert type(mock_response) == type(real_response)\nassert hasattr(mock_response, \'content\')\nassert hasattr(mock_response, \'tokens_used\')\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-2-scenario-based-testing",children:"\ud83c\udfad Best Practice #2: Scenario-Based Testing"}),"\n",(0,i.jsx)(n.h3,{id:"requirement-support-different-mock-scenarios-success-failure-edge-cases-113",children:"Requirement: Support different mock scenarios (success, failure, edge cases) (11.3)"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Scenarios Implemented:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class MockScenario(Enum):\n    SUCCESS = "success"              # Normal successful validation\n    HIGH_QUALITY = "high_quality"    # High quality content (>90% score)\n    LOW_QUALITY = "low_quality"      # Low quality content (<70% score)\n    FAILURE = "failure"              # Validation failure\n    TIMEOUT = "timeout"              # AI timeout simulation\n    RATE_LIMIT = "rate_limit"        # Rate limiting simulation\n    INVALID_RESPONSE = "invalid_response"  # Malformed AI response\n    PARTIAL_FAILURE = "partial_failure"    # Partial validation failure\n    EDGE_CASE = "edge_case"          # Edge cases (empty content, etc.)\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Cover all possible AI response scenarios"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Test both positive and negative cases"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Include realistic error conditions"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Simulate network and API issues"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Test edge cases and boundary conditions"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Test all scenarios for comprehensive coverage\nscenarios_to_test = [\n    MockScenario.SUCCESS,\n    MockScenario.HIGH_QUALITY,\n    MockScenario.LOW_QUALITY,\n    MockScenario.FAILURE,\n    MockScenario.EDGE_CASE\n]\n\nfor scenario in scenarios_to_test:\n    response = await mock_manager.get_ai_response(\n        prompt="Test validation",\n        validator_id="content_validator",\n        scenario=scenario,\n        use_mock=True\n    )\n    # Verify response matches scenario expectations\n    assert_scenario_response(response, scenario)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-3-record-and-playback-system",children:"\ud83d\udcf9 Best Practice #3: Record and Playback System"}),"\n",(0,i.jsx)(n.h3,{id:"requirement-allow-recording-and-playback-of-ai-interactions-for-consistent-testing-112",children:"Requirement: Allow recording and playback of AI interactions for consistent testing (11.2)"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Implementation:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'@dataclass\nclass RecordedInteraction:\n    """Recorded AI interaction for playback"""\n    interaction_id: str\n    request_hash: str        # Hash of prompt + context\n    prompt: str\n    response: MockResponse\n    validator_id: str\n    content_type: str\n    timestamp: datetime\n    real_ai_used: bool = True\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Record real AI interactions during development"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Use deterministic hashing for consistent playback"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Store recordings in version control for team consistency"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Sanitize sensitive data in recordings"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Support recording updates when AI behavior changes"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Record real AI interaction (when OPENAI_API_KEY is set)\nexport OPENAI_API_KEY="your-key"\nreal_response = await mock_manager.get_ai_response(\n    prompt="Validate chapter content",\n    validator_id="content_validator",\n    content_type="chapter",\n    model="gpt-4"\n)\n# Automatically recorded to disk\n\n# Later, playback the recorded interaction (when OPENAI_API_KEY is empty)\nunset OPENAI_API_KEY\nplayback_response = await mock_manager.get_ai_response(\n    prompt="Validate chapter content",  # Same prompt\n    validator_id="content_validator",\n    content_type="chapter",\n    model="gpt-4"\n)\n\n# Responses are identical for deterministic testing\nassert playback_response.content == real_response.content\n'})}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-best-practice-4-api-key-based-switching",children:"\u2699\ufe0f Best Practice #4: API Key-Based Switching"}),"\n",(0,i.jsx)(n.h3,{id:"requirement-use-configuration-flags-without-code-changes-116",children:"Requirement: Use configuration flags without code changes (11.6)"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Environment-Based Configuration:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Mock Mode (Development/Testing)\nunset OPENAI_API_KEY  # or leave empty\n\n# Real AI Mode (Production/Recording)\nexport OPENAI_API_KEY="your-openai-key"\nexport OPENAI_BASE_URL="https://your-litellm-proxy.com/v1"  # Optional\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Automatic Mode Detection:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class AIMockManager:\n    def __init__(self):\n        self.openai_api_key = os.getenv("OPENAI_API_KEY", "")\n        self.use_mock_mode = not bool(self.openai_api_key.strip())\n\n        if not self.use_mock_mode:\n            self.openai_client = AsyncOpenAI(\n                api_key=self.openai_api_key,\n                base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")\n            )\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Use environment variables for seamless switching"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 No code changes required to switch modes"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Transparent LiteLLM proxy integration"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Automatic mode detection based on API key presence"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Support different environments (dev/test/prod)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Same code works in both modes\nmock_manager = AIMockManager()  # Automatically detects mode\n\nresponse = await mock_manager.get_ai_response(\n    prompt="Validate this content",\n    validator_id="content_validator",\n    content_type="chapter",\n    model="gpt-4"\n)\n\n# Process response (identical for mock or real AI)\nresult_data = json.loads(response.content)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-5-coverage-and-metrics",children:"\ud83d\udcca Best Practice #5: Coverage and Metrics"}),"\n",(0,i.jsx)(n.h3,{id:"requirement-provide-metrics-on-test-coverage-and-validation-accuracy-115",children:"Requirement: Provide metrics on test coverage and validation accuracy (11.5)"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Coverage Areas:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Validator Coverage"})," - Which validators have been tested"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scenario Coverage"})," - Which mock scenarios have been exercised"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Content Type Coverage"})," - Which content types have been validated"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Code Path Coverage"})," - Which code paths within validators have been executed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"AI Interaction Coverage"})," - Which AI interaction patterns have been tested"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Metrics Tracked:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"@dataclass\nclass CoverageMetrics:\n    total_items: int\n    covered_items: int\n    coverage_percentage: float\n    uncovered_items: List[str]\n    details: Dict[str, Any]\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Track coverage across multiple dimensions"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Set minimum coverage thresholds (e.g., 80%)"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Generate actionable recommendations"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Monitor coverage trends over time"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Include accuracy metrics for known-good/bad content"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Generate comprehensive coverage report\ncoverage_reporter = CoverageReporter()\ncoverage_report = await coverage_reporter.generate_coverage_report(test_results)\n\nprint(f"Overall Coverage: {coverage_report.overall_coverage.coverage_percentage:.1f}%")\n\n# Validator coverage\nfor validator_id, metrics in coverage_report.validator_coverage.items():\n    print(f"{validator_id}: {metrics.coverage_percentage:.1f}% coverage")\n\n# Recommendations for improvement\nfor recommendation in coverage_report.recommendations:\n    print(f"\ud83d\udca1 {recommendation}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-6-comprehensive-test-framework",children:"\ud83e\uddea Best Practice #6: Comprehensive Test Framework"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Test Framework Components:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test Case Generation"})," - Automated test case creation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parallel Execution"})," - Efficient test execution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Result Aggregation"})," - Comprehensive result analysis"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regression Testing"})," - Compare against baselines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Accuracy Validation"})," - Test with known-good/bad content"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Generate test cases automatically for all validator/scenario combinations"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Support parallel test execution for performance"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Include timeout handling for robust testing"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Provide detailed failure analysis"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Support regression testing against baselines"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Create comprehensive test suite\ntest_framework = ValidationTestFramework(mock_manager)\n\ntest_cases = await test_framework.create_comprehensive_test_suite(\n    validators=["content_validator", "quality_validator"],\n    content_types=["chapter", "manuscript"]\n)\n\n# Run tests in parallel\ntest_report = await test_framework.run_test_suite(\n    test_cases=test_cases,\n    parallel=True,\n    max_workers=10\n)\n\nprint(f"Tests: {test_report[\'summary\'][\'total_tests\']}")\nprint(f"Success Rate: {test_report[\'summary\'][\'success_rate\']:.1f}%")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-7-live-response-population",children:"\ud83d\udcf9 Best Practice #7: Live Response Population"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Populating Mock Data from Real AI:"}),"\nThe system can automatically populate mock input/output mappings from live AI responses, providing realistic test data."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Bulk Recording:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Define prompts to record from live AI\nprompts_to_record = [\n    {\n        "prompt": "Analyze this chapter for tone consistency",\n        "validator_id": "content_validator",\n        "content_type": "chapter",\n        "expected_scenario": "success"\n    },\n    {\n        "prompt": "Check manuscript publishing standards",\n        "validator_id": "publishing_standards_validator",\n        "content_type": "manuscript",\n        "expected_scenario": "success"\n    },\n    {\n        "prompt": "Validate poor quality content",\n        "validator_id": "content_validator",\n        "content_type": "chapter",\n        "expected_scenario": "low_quality"\n    }\n]\n\n# Record all prompts from live AI (requires OPENAI_API_KEY)\nresults = await mock_manager.populate_mock_mappings_from_live(\n    prompts=prompts_to_record,\n    model="gpt-4"\n)\n\nprint(f"Recorded {results[\'successful_recordings\']} interactions")\nprint(f"Total cost: ${sum(r[\'cost\'] for r in results[\'recordings\']):.4f}")\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Automatic Recording:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Every real AI call is automatically recorded\nexport OPENAI_API_KEY="your-key"\n\nresponse = await mock_manager.get_ai_response(\n    prompt="Any validation prompt",\n    validator_id="any_validator",\n    content_type="chapter",\n    model="gpt-4"\n)\n# This interaction is automatically saved for future mock use\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Record comprehensive test scenarios during development"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Include edge cases and failure scenarios in recordings"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Monitor recording costs and token usage"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Version control recorded interactions for team consistency"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Update recordings when AI behavior changes"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-8-accuracy-validation",children:"\ud83c\udfaf Best Practice #8: Accuracy Validation"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Accuracy Testing Approach:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Known-Good Content"})," - Content that should pass validation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Known-Bad Content"})," - Content that should fail validation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Boundary Testing"})," - Content at quality thresholds"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consistency Testing"})," - Same content should produce same results"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Create curated datasets of known-good and known-bad content"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Test validator accuracy against expected outcomes"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Measure consistency of mock responses"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Validate that mock behavior matches real AI patterns"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Track accuracy metrics over time"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Test with known-good content\ngood_content = await test_data_generator.generate_known_good_content(\n    "chapter", "content_validator"\n)\n\nresponse = await mock_manager.get_ai_response(\n    prompt="Validate known-good content",\n    validator_id="content_validator",\n    scenario=MockScenario.HIGH_QUALITY,\n    use_mock=True\n)\n\n# Verify response indicates high quality\nresponse_data = json.loads(response.content)\nassert response_data["validation_score"] > 90.0\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-8-regression-testing",children:"\ud83d\udd04 Best Practice #8: Regression Testing"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Regression Testing Strategy:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Baseline Establishment"})," - Save current test results as baseline"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Comparison Analysis"})," - Compare new results against baseline"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regression Detection"})," - Identify tests that now fail"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Improvement Tracking"})," - Track tests that now pass"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Trend Analysis"})," - Monitor quality trends over time"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Establish baselines after major releases"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Run regression tests on every code change"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Alert on regressions immediately"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Track improvements and celebrate wins"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Maintain historical trend data"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Save current results as baseline\nawait test_framework.save_as_baseline()\n\n# Later, run regression tests\nregression_report = await test_framework.run_regression_tests()\n\nif regression_report["regression_summary"]["regressions_count"] > 0:\n    print("\u26a0\ufe0f  Regressions detected!")\n    for regression in regression_report["details"]["regressions"]:\n        print(f"\u274c {regression[\'test_id\']}: {regression[\'error\']}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-9-performance-testing",children:"\ud83d\ude80 Best Practice #9: Performance Testing"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Performance Considerations:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mock Response Speed"})," - Simulate realistic AI response times"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parallel Processing"})," - Test concurrent validation requests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resource Usage"})," - Monitor memory and CPU usage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Timeout Handling"})," - Test timeout scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Rate Limiting"})," - Simulate API rate limits"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Include realistic delays in mock responses"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Test system behavior under load"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Monitor resource consumption during tests"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Test timeout and retry mechanisms"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Validate rate limiting behavior"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Test with realistic delays\nasync def _generate_scenario_response(self, scenario):\n    # Simulate AI processing delay\n    if scenario == MockScenario.SUCCESS:\n        await asyncio.sleep(0.5)  # Realistic delay\n    elif scenario == MockScenario.TIMEOUT:\n        await asyncio.sleep(30)   # Timeout scenario\n\n    return self._create_response(scenario)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"-best-practice-10-monitoring-and-alerting",children:"\ud83d\udcc8 Best Practice #10: Monitoring and Alerting"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitoring Areas:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test Success Rates"})," - Track test pass/fail rates"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Coverage Trends"})," - Monitor coverage over time"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance Metrics"})," - Track test execution times"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mock Usage"})," - Monitor mock vs real AI usage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error Patterns"})," - Identify common failure modes"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Set up automated monitoring dashboards"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Alert on coverage drops or test failures"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Track key metrics over time"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Monitor mock system health"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Generate regular reports for stakeholders"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-implementation-checklist",children:"\ud83d\udee0\ufe0f Implementation Checklist"}),"\n",(0,i.jsx)(n.h3,{id:"phase-1-basic-mock-system",children:"Phase 1: Basic Mock System"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement ",(0,i.jsx)(n.code,{children:"AIMockManager"})," with interface consistency"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Create scenario-based response generation"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add configuration-driven switching"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement basic test framework"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-2-advanced-features",children:"Phase 2: Advanced Features"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add record and playback system"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement comprehensive coverage reporting"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Create test data generation utilities"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add regression testing capabilities"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-3-production-readiness",children:"Phase 3: Production Readiness"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add performance testing and monitoring"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement trend analysis and alerting"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Create documentation and examples"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Set up CI/CD integration"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-4-optimization",children:"Phase 4: Optimization"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Optimize mock response generation"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add advanced accuracy validation"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Implement intelligent test case generation"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Add machine learning for mock improvement"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-usage-examples",children:"\ud83d\udcda Usage Examples"}),"\n",(0,i.jsx)(n.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Initialize mock manager\nmock_manager = AIMockManager(mock_data_dir=".libriscribe2/mock_data")\n\n# Get mock response\nresponse = await mock_manager.get_ai_response(\n    prompt="Validate this content",\n    validator_id="content_validator",\n    content_type="chapter",\n    scenario=MockScenario.SUCCESS,\n    use_mock=True\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"test-framework-usage",children:"Test Framework Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Create test framework\ntest_framework = ValidationTestFramework(mock_manager)\n\n# Generate comprehensive test suite\ntest_cases = await test_framework.create_comprehensive_test_suite(\n    validators=["content_validator", "quality_validator"],\n    content_types=["chapter", "manuscript"]\n)\n\n# Run tests\nreport = await test_framework.run_test_suite(test_cases)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"coverage-analysis",children:"Coverage Analysis"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Generate coverage report\ncoverage_reporter = CoverageReporter()\ncoverage_report = await coverage_reporter.generate_coverage_report(test_results)\n\n# Check coverage thresholds\nif coverage_report.overall_coverage.coverage_percentage < 80:\n    print("\u26a0\ufe0f  Coverage below threshold!")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-key-benefits",children:"\ud83c\udfaf Key Benefits"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost Efficiency"})," - Avoid expensive AI API calls during testing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deterministic Testing"})," - Consistent, repeatable test results"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Comprehensive Coverage"})," - Test all scenarios including edge cases"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fast Feedback"})," - Quick test execution without AI delays"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Offline Testing"})," - Test without internet connectivity"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regression Prevention"})," - Catch issues before they reach production"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Quality Assurance"})," - Ensure validation accuracy and reliability"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-compliance-with-requirements",children:"\ud83d\udccb Compliance with Requirements"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Requirement"}),(0,i.jsx)(n.th,{children:"Implementation"}),(0,i.jsx)(n.th,{children:"Status"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.1 - Mock AI responses simulate real behavior"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"MockResponse"})," class with realistic data"]}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.2 - Record and playback interactions"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"RecordedInteraction"})," system"]}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.3 - Support different scenarios"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"MockScenario"})," enum with 9 scenarios"]}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.4 - Same interface as real AI"}),(0,i.jsx)(n.td,{children:"Identical response structures"}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.5 - Test coverage and accuracy metrics"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"CoverageReporter"})," and accuracy validation"]}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"11.6 - Configuration flags for switching"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"ValidationConfig.ai_mock_enabled"})}),(0,i.jsx)(n.td,{children:"\u2705 Complete"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"-getting-started",children:"\ud83d\ude80 Getting Started"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Install Dependencies"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install -r requirements.txt\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Run Example"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python examples/ai_testing_best_practices.py\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"View Results"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ls .demo/test_data/     # Test results\nls .demo/coverage_data/ # Coverage reports\nls .demo/mock_data/     # Mock data\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Integrate with Your Validators"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from src.libriscribe2.validation.ai_mock import AIMockManager\n\nmock_manager = AIMockManager()\n# Use in your validator implementations\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This comprehensive AI testing and mock system ensures reliable, efficient, and thorough testing of the LibriScribe validation system while meeting all requirements and following industry best practices."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>c});var t=s(6540);const i={},r=t.createContext(i);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);