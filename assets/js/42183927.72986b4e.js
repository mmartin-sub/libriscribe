"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[819],{398:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"validation_utils_signatures","title":"LibriScribe Validation Utils - Function and Class Signatures","description":"Overview","source":"@site/docs/validation_utils_signatures.md","sourceDirName":".","slug":"/validation_utils_signatures","permalink":"/libriscribe2/docs/validation_utils_signatures","draft":false,"unlisted":false,"editUrl":"https://github.com/guerra2fernando/libriscribe2/tree/main/docs/docs/validation_utils_signatures.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"LibriScribe Validation Interfaces - Function and Class Signatures","permalink":"/libriscribe2/docs/validation_interfaces_signatures"}}');var i=t(4848),s=t(8453);const a={},o="LibriScribe Validation Utils - Function and Class Signatures",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Current Module Structure",id:"current-module-structure",level:2},{value:"<code>src/libriscribe2/validation/utils/__init__.py</code>",id:"srclibriscribe2validationutils__init__py",level:3},{value:"Planned Interface Implementations",id:"planned-interface-implementations",level:2},{value:"ResourceManagerImpl",id:"resourcemanagerimpl",level:3},{value:"HealthMonitorImpl",id:"healthmonitorimpl",level:3},{value:"AIUsageTrackerImpl",id:"aiusagetrackerimpl",level:3},{value:"ReportGeneratorImpl",id:"reportgeneratorimpl",level:3},{value:"Utility Functions",id:"utility-functions",level:2},{value:"File and Path Utilities",id:"file-and-path-utilities",level:3},{value:"Configuration Utilities",id:"configuration-utilities",level:3},{value:"Monitoring Utilities",id:"monitoring-utilities",level:3},{value:"Type Definitions",id:"type-definitions",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"Integration Points",id:"integration-points",level:2},{value:"Version Information",id:"version-information",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"libriscribe-validation-utils---function-and-class-signatures",children:"LibriScribe Validation Utils - Function and Class Signatures"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This document provides detailed function and class signatures for the LibriScribe validation utils package. The utils package contains utility implementations that support the core validation system."}),"\n",(0,i.jsx)(n.h2,{id:"current-module-structure",children:"Current Module Structure"}),"\n",(0,i.jsx)(n.h3,{id:"srclibriscribe2validationutils__init__py",children:(0,i.jsx)(n.code,{children:"src/libriscribe2/validation/utils/__init__.py"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nUtility modules for the LibriScribe validation system.\n\nThis package contains utility classes and functions used across the validation system.\n"""\n\n# Type-annotated exports list\n__all__: list[str] = [\n    # Utility classes will be added here as they are implemented\n]\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Current Exports"}),": None (package is in initial setup phase)"]}),"\n",(0,i.jsx)(n.h2,{id:"planned-interface-implementations",children:"Planned Interface Implementations"}),"\n",(0,i.jsx)(n.h3,{id:"resourcemanagerimpl",children:"ResourceManagerImpl"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Interface"}),": ",(0,i.jsx)(n.code,{children:"libriscribe2.validation.interfaces.ResourceManager"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ResourceManagerImpl(ResourceManager):\n    """\n    Implementation of resource management for validation processes.\n\n    Manages temporary workspaces, file operations, and resource cleanup\n    for validation operations.\n    """\n\n    def __init__(\n        self,\n        base_temp_dir: Optional[str] = None,\n        auto_cleanup: bool = True,\n        max_workspace_age: int = 3600\n    ) -> None:\n        """\n        Initialize resource manager.\n\n        Args:\n            base_temp_dir: Base directory for temporary workspaces\n            auto_cleanup: Whether to automatically cleanup old workspaces\n            max_workspace_age: Maximum age of workspace in seconds before cleanup\n        """\n\n    async def create_workspace(self, project_id: str) -> str:\n        """\n        Create unique workspace for validation process.\n\n        Args:\n            project_id: Unique identifier for the project\n\n        Returns:\n            Path to created workspace directory\n\n        Raises:\n            ResourceError: If workspace creation fails\n        """\n\n    async def cleanup_workspace(self, workspace_path: str) -> None:\n        """\n        Clean up workspace and temporary files.\n\n        Args:\n            workspace_path: Path to workspace to clean up\n\n        Raises:\n            ResourceError: If cleanup fails\n        """\n\n    async def get_unique_temp_file(\n        self,\n        workspace: str,\n        suffix: str = "",\n        prefix: str = "temp_"\n    ) -> str:\n        """\n        Get unique temporary file path within workspace.\n\n        Args:\n            workspace: Workspace directory path\n            suffix: File suffix/extension\n            prefix: File prefix\n\n        Returns:\n            Path to unique temporary file\n\n        Raises:\n            ResourceError: If file creation fails\n        """\n\n    async def get_workspace_info(self, workspace_path: str) -> Dict[str, Any]:\n        """\n        Get information about workspace.\n\n        Args:\n            workspace_path: Path to workspace\n\n        Returns:\n            Dictionary containing workspace information:\n            - created_at: Workspace creation timestamp\n            - size_bytes: Total size of workspace in bytes\n            - file_count: Number of files in workspace\n            - project_id: Associated project ID\n        """\n\n    async def list_workspaces(self) -> List[Dict[str, Any]]:\n        """\n        List all active workspaces.\n\n        Returns:\n            List of workspace information dictionaries\n        """\n\n    async def cleanup_old_workspaces(self, max_age: Optional[int] = None) -> int:\n        """\n        Clean up workspaces older than specified age.\n\n        Args:\n            max_age: Maximum age in seconds (uses instance default if None)\n\n        Returns:\n            Number of workspaces cleaned up\n        """\n'})}),"\n",(0,i.jsx)(n.h3,{id:"healthmonitorimpl",children:"HealthMonitorImpl"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Interface"}),": ",(0,i.jsx)(n.code,{children:"libriscribe2.validation.interfaces.HealthMonitor"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class HealthMonitorImpl(HealthMonitor):\n    """\n    Implementation of system health monitoring.\n\n    Monitors system resources, AI service connectivity, and validation\n    system performance metrics.\n    """\n\n    def __init__(\n        self,\n        check_interval: int = 60,\n        ai_timeout: int = 30,\n        memory_threshold: float = 0.8,\n        disk_threshold: float = 0.9\n    ) -> None:\n        """\n        Initialize health monitor.\n\n        Args:\n            check_interval: Health check interval in seconds\n            ai_timeout: AI connectivity check timeout in seconds\n            memory_threshold: Memory usage threshold (0.0-1.0)\n            disk_threshold: Disk usage threshold (0.0-1.0)\n        """\n\n    async def get_health_status(self) -> Dict[str, Any]:\n        """\n        Get current system health status.\n\n        Returns:\n            Dictionary containing health status:\n            - overall_status: "healthy" | "warning" | "critical"\n            - timestamp: Current timestamp\n            - system_resources: CPU, memory, disk usage\n            - ai_services: AI service connectivity status\n            - validation_engine: Validation engine status\n            - active_validations: Number of active validation processes\n        """\n\n    async def get_metrics(self) -> Dict[str, Any]:\n        """\n        Get comprehensive system metrics.\n\n        Returns:\n            Dictionary containing detailed metrics:\n            - performance: Response times, throughput\n            - resources: Detailed resource usage\n            - errors: Error rates and types\n            - ai_usage: AI service usage statistics\n            - validation_stats: Validation success/failure rates\n        """\n\n    async def check_ai_connectivity(self) -> bool:\n        """\n        Check AI service connectivity status.\n\n        Returns:\n            True if AI services are accessible, False otherwise\n        """\n\n    async def get_system_resources(self) -> Dict[str, Any]:\n        """\n        Get current system resource usage.\n\n        Returns:\n            Dictionary containing:\n            - cpu_percent: CPU usage percentage\n            - memory_percent: Memory usage percentage\n            - disk_percent: Disk usage percentage\n            - network_io: Network I/O statistics\n        """\n\n    async def start_monitoring(self) -> None:\n        """Start continuous health monitoring."""\n\n    async def stop_monitoring(self) -> None:\n        """Stop continuous health monitoring."""\n\n    async def get_health_history(\n        self,\n        hours: int = 24\n    ) -> List[Dict[str, Any]]:\n        """\n        Get health status history.\n\n        Args:\n            hours: Number of hours of history to retrieve\n\n        Returns:\n            List of historical health status entries\n        """\n'})}),"\n",(0,i.jsx)(n.h3,{id:"aiusagetrackerimpl",children:"AIUsageTrackerImpl"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Interface"}),": ",(0,i.jsx)(n.code,{children:"libriscribe2.validation.interfaces.AIUsageTracker"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class AIUsageTrackerImpl(AIUsageTracker):\n    """\n    Implementation of AI usage tracking and cost monitoring.\n\n    Tracks AI API usage, costs, and performance metrics across\n    validation processes.\n    """\n\n    def __init__(\n        self,\n        storage_backend: str = "sqlite",\n        cost_tracking: bool = True,\n        performance_tracking: bool = True\n    ) -> None:\n        """\n        Initialize AI usage tracker.\n\n        Args:\n            storage_backend: Storage backend for usage data\n            cost_tracking: Whether to track costs\n            performance_tracking: Whether to track performance metrics\n        """\n\n    async def track_request(\n        self,\n        project_id: str,\n        validator_id: str,\n        tokens_used: int,\n        cost: float,\n        model: str,\n        request_id: Optional[str] = None,\n        response_time: Optional[float] = None,\n        success: bool = True\n    ) -> None:\n        """\n        Track AI request usage and costs.\n\n        Args:\n            project_id: Project identifier\n            validator_id: Validator that made the request\n            tokens_used: Number of tokens consumed\n            cost: Cost of the request in USD\n            model: AI model used\n            request_id: Optional request identifier\n            response_time: Request response time in seconds\n            success: Whether the request was successful\n        """\n\n    async def get_project_usage(self, project_id: str) -> Dict[str, Any]:\n        """\n        Get AI usage statistics for specific project.\n\n        Args:\n            project_id: Project identifier\n\n        Returns:\n            Dictionary containing:\n            - total_requests: Total number of requests\n            - total_tokens: Total tokens used\n            - total_cost: Total cost in USD\n            - models_used: List of models used\n            - validators: Usage by validator\n            - time_range: First and last request timestamps\n        """\n\n    async def get_usage_report(\n        self,\n        project_id: str,\n        start_date: Optional[datetime] = None,\n        end_date: Optional[datetime] = None\n    ) -> Dict[str, Any]:\n        """\n        Generate comprehensive usage report.\n\n        Args:\n            project_id: Project identifier\n            start_date: Report start date (optional)\n            end_date: Report end date (optional)\n\n        Returns:\n            Detailed usage report with charts and analytics\n        """\n\n    async def get_cost_breakdown(\n        self,\n        project_id: str\n    ) -> Dict[str, Any]:\n        """\n        Get detailed cost breakdown for project.\n\n        Args:\n            project_id: Project identifier\n\n        Returns:\n            Cost breakdown by model, validator, and time period\n        """\n\n    async def get_performance_metrics(\n        self,\n        project_id: str\n    ) -> Dict[str, Any]:\n        """\n        Get AI performance metrics for project.\n\n        Args:\n            project_id: Project identifier\n\n        Returns:\n            Performance metrics including response times and success rates\n        """\n\n    async def export_usage_data(\n        self,\n        project_id: str,\n        format: str = "csv"\n    ) -> str:\n        """\n        Export usage data in specified format.\n\n        Args:\n            project_id: Project identifier\n            format: Export format ("csv", "json", "xlsx")\n\n        Returns:\n            Path to exported file\n        """\n'})}),"\n",(0,i.jsx)(n.h3,{id:"reportgeneratorimpl",children:"ReportGeneratorImpl"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Interface"}),": ",(0,i.jsx)(n.code,{children:"libriscribe2.validation.interfaces.ReportGenerator"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ReportGeneratorImpl(ReportGenerator):\n    """\n    Implementation of validation report generation.\n\n    Generates validation reports in multiple formats with customizable\n    templates and styling.\n    """\n\n    def __init__(\n        self,\n        template_dir: Optional[str] = None,\n        output_dir: Optional[str] = None,\n        default_format: str = "html"\n    ) -> None:\n        """\n        Initialize report generator.\n\n        Args:\n            template_dir: Directory containing report templates\n            output_dir: Default output directory for reports\n            default_format: Default report format\n        """\n\n    async def generate_report(\n        self,\n        result: ValidationResult,\n        format: str,\n        output_path: Optional[str] = None,\n        template: Optional[str] = None,\n        include_charts: bool = True\n    ) -> Dict[str, Any]:\n        """\n        Generate validation report in specified format.\n\n        Args:\n            result: Validation result to generate report for\n            format: Output format ("html", "pdf", "json", "csv")\n            output_path: Custom output path (optional)\n            template: Custom template name (optional)\n            include_charts: Whether to include charts and visualizations\n\n        Returns:\n            Dictionary containing:\n            - report_path: Path to generated report\n            - format: Report format\n            - size_bytes: Report file size\n            - generation_time: Time taken to generate report\n        """\n\n    async def get_supported_formats(self) -> List[str]:\n        """\n        Get list of supported report formats.\n\n        Returns:\n            List of supported format strings\n        """\n\n    async def generate_summary_report(\n        self,\n        results: List[ValidationResult],\n        format: str = "html"\n    ) -> Dict[str, Any]:\n        """\n        Generate summary report for multiple validation results.\n\n        Args:\n            results: List of validation results\n            format: Output format\n\n        Returns:\n            Generated summary report information\n        """\n\n    async def create_custom_template(\n        self,\n        template_name: str,\n        template_content: str,\n        format: str\n    ) -> bool:\n        """\n        Create custom report template.\n\n        Args:\n            template_name: Name for the template\n            template_content: Template content/markup\n            format: Target format for template\n\n        Returns:\n            True if template was created successfully\n        """\n\n    async def list_templates(self) -> Dict[str, List[str]]:\n        """\n        List available report templates.\n\n        Returns:\n            Dictionary mapping formats to available template names\n        """\n\n    async def generate_chart_data(\n        self,\n        result: ValidationResult\n    ) -> Dict[str, Any]:\n        """\n        Generate chart data for visualization.\n\n        Args:\n            result: Validation result\n\n        Returns:\n            Chart data suitable for visualization libraries\n        """\n'})}),"\n",(0,i.jsx)(n.h2,{id:"utility-functions",children:"Utility Functions"}),"\n",(0,i.jsx)(n.h3,{id:"file-and-path-utilities",children:"File and Path Utilities"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def get_project_workspace_path(project_id: str, base_dir: str) -> str:\n    """\n    Get standardized workspace path for project.\n\n    Args:\n        project_id: Project identifier\n        base_dir: Base directory for workspaces\n\n    Returns:\n        Standardized workspace path\n    """\n\ndef ensure_directory_exists(path: str) -> None:\n    """\n    Ensure directory exists, creating if necessary.\n\n    Args:\n        path: Directory path to ensure exists\n\n    Raises:\n        ResourceError: If directory cannot be created\n    """\n\ndef safe_file_operation(\n    operation: Callable[[], Any],\n    error_message: str\n) -> Any:\n    """\n    Safely execute file operation with error handling.\n\n    Args:\n        operation: File operation to execute\n        error_message: Error message for failures\n\n    Returns:\n        Operation result\n\n    Raises:\n        ResourceError: If operation fails\n    """\n'})}),"\n",(0,i.jsx)(n.h3,{id:"configuration-utilities",children:"Configuration Utilities"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def load_utility_config(\n    config_path: str,\n    utility_name: str\n) -> Dict[str, Any]:\n    """\n    Load configuration for specific utility.\n\n    Args:\n        config_path: Path to configuration file\n        utility_name: Name of utility to load config for\n\n    Returns:\n        Utility-specific configuration\n    """\n\ndef validate_config_schema(\n    config: Dict[str, Any],\n    schema: Dict[str, Any]\n) -> bool:\n    """\n    Validate configuration against schema.\n\n    Args:\n        config: Configuration to validate\n        schema: Configuration schema\n\n    Returns:\n        True if configuration is valid\n\n    Raises:\n        ConfigurationError: If configuration is invalid\n    """\n'})}),"\n",(0,i.jsx)(n.h3,{id:"monitoring-utilities",children:"Monitoring Utilities"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def format_bytes(bytes_value: int) -> str:\n    """\n    Format byte value as human-readable string.\n\n    Args:\n        bytes_value: Number of bytes\n\n    Returns:\n        Formatted string (e.g., "1.5 GB")\n    """\n\ndef calculate_health_score(metrics: Dict[str, Any]) -> float:\n    """\n    Calculate overall health score from metrics.\n\n    Args:\n        metrics: System metrics dictionary\n\n    Returns:\n        Health score between 0.0 and 1.0\n    """\n\ndef get_system_info() -> Dict[str, Any]:\n    """\n    Get basic system information.\n\n    Returns:\n        Dictionary containing system information\n    """\n'})}),"\n",(0,i.jsx)(n.h2,{id:"type-definitions",children:"Type Definitions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from typing import TypedDict, Literal, Union\nfrom datetime import datetime\n\nclass WorkspaceInfo(TypedDict):\n    """Type definition for workspace information."""\n    path: str\n    project_id: str\n    created_at: datetime\n    size_bytes: int\n    file_count: int\n\nclass HealthStatus(TypedDict):\n    """Type definition for health status."""\n    overall_status: Literal["healthy", "warning", "critical"]\n    timestamp: datetime\n    system_resources: Dict[str, float]\n    ai_services: bool\n    validation_engine: str\n    active_validations: int\n\nclass UsageMetrics(TypedDict):\n    """Type definition for AI usage metrics."""\n    total_requests: int\n    total_tokens: int\n    total_cost: float\n    models_used: List[str]\n    validators: Dict[str, Dict[str, Union[int, float]]]\n    time_range: Dict[str, datetime]\n\nReportFormat = Literal["html", "pdf", "json", "csv", "xlsx"]\nStorageBackend = Literal["sqlite", "postgresql", "memory"]\n'})}),"\n",(0,i.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,i.jsx)(n.p,{children:"All utility implementations use the validation system's exception hierarchy:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from libriscribe2.validation.interfaces import (\n    ValidationError,\n    ResourceError,\n    ConfigurationError\n)\n\n# Resource-related errors\nclass WorkspaceError(ResourceError):\n    """Raised when workspace operations fail."""\n\nclass FileOperationError(ResourceError):\n    """Raised when file operations fail."""\n\n# Monitoring-related errors\nclass HealthCheckError(ValidationError):\n    """Raised when health checks fail."""\n\nclass MetricsError(ValidationError):\n    """Raised when metrics collection fails."""\n\n# Usage tracking errors\nclass UsageTrackingError(ValidationError):\n    """Raised when usage tracking fails."""\n\nclass ReportGenerationError(ValidationError):\n    """Raised when report generation fails."""\n'})}),"\n",(0,i.jsx)(n.h2,{id:"integration-points",children:"Integration Points"}),"\n",(0,i.jsx)(n.p,{children:"The utility implementations integrate with the validation system through:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration System"}),": All utilities accept ",(0,i.jsx)(n.code,{children:"ValidationConfig"})," objects"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Interface Contracts"}),": Implement abstract interfaces from ",(0,i.jsx)(n.code,{children:"validation.interfaces"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error Handling"}),": Use validation system exception hierarchy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Logging"}),": Integrate with validation system logging"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Async Support"}),": All operations are async-compatible"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"version-information",children:"Version Information"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Package Version"}),": 1.0.0"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Python Compatibility"}),": 3.8+"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dependencies"}),": See ",(0,i.jsx)(n.code,{children:"pyproject.toml"})," for full dependency list"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Interface Compatibility"}),": Compatible with ",(0,i.jsx)(n.code,{children:"libriscribe2.validation.interfaces"})," v1.0.0"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var r=t(6540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);